import json
import nltk

from nltk.compat import iteritems

# Load in human language data from wherever you've saved it
USER_ID = '107033731246200681024' #Tim O' Reilly
USER_I = 'QueryBy_Id_Output'

DATA = USER_ID + '.json'
data = json.loads(open(DATA).read())

# Number of collocations to find
N = 25

all_tokens = [token for activity in data for token in activity['object']['content'
].lower().split()]


corpus={}
i=0
for activity in data:
 corpus[i]=' '.join( activity['object']['content'].lower().split() )
 i=i+1

print corpus[3]
'''
Print Corpus

for key in corpus:
 print corpus[key]
 print 
 print
 if key==3:
  break
print corpus[1]
'''

finder = nltk.BigramCollocationFinder.from_words(all_tokens)

finder.apply_freq_filter(2)

finder.apply_word_filter(lambda w: w in nltk.corpus.stopwords.words('english'))

scorer = nltk.metrics.BigramAssocMeasures.jaccard

collocations = finder.nbest(scorer, N)

for collocation in collocations:
    print collocation
    c = ' '.join(collocation)
    print c
    
